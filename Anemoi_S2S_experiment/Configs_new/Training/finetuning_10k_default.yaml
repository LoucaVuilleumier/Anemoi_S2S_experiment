defaults:
- data: zarr
- dataloader: native_grid
- datamodule: single
- diagnostics: evaluation
- hardware: slurm
- graph: encoder_decoder_only
- model: transformer
- training: default
- _self_

config_validation: False

### This file is for local experimentation.
##  When you commit your changes, assign the new features and keywords
##  to the correct defaults.
# For example to change from default GPU count:
# hardware:
#   num_gpus_per_node: 1


data:
  normalizer:
    default: "mean-std"

diagnostics:
  log:
    mlflow:
      enabled: True
      offline: True
      authentication: True
      experiment_name: 'Louca_Vuilleumier_KNMI_S2S_experiment'
      project_name: 'Anemoi'
      log_model: False
      tracking_uri: 'https://mlflow.ecmwf.int'
      http_max_retries: 2
      run_name: 'finetuning_10k_default'
    wandb:
      enabled: False
      entity: None

hardware:
  accelerator: auto
  num_gpus_per_model: 1
  paths:
    data: "/home/mlx/ai-ml/datasets/"
    output: "./output_training/"
    graph: "./graphs/"
    warm_start: "/ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/checkpoints_mariana/louca/"

  files:
    dataset: aifs-ea-an-oper-0001-mars-o96-1979-2023-6h-v8.zarr
    graph: graph.pkl
    warm_start: last.ckpt
  

model:
  keep_batch_sharded: True
  num_channels: 1024
dataloader:
  limit_batches:
    training: null
    validation: 100

training:
  max_steps: 320001  # Checkpoint is at 310001 steps (Mariana checkpoint) + 10000 additional steps
  max_epochs: null
  lr:
    #warmup: 1000
    rate: 2.5e-4 #6.25e-5 * 4 (scaled for 4 GPUs)
    iterations: ${training.max_steps}
    min: 1.2e-6 #3e-7 * 4 (scaled for 4 GPUs)

