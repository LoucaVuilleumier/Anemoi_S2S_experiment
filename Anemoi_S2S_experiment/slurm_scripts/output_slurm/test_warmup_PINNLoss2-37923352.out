[ECMWF-INFO -sbatch] - -------------------------------------------------------------------------------------
[ECMWF-INFO -sbatch] -  This is the ECMWF jobfilter
[ECMWF-INFO -sbatch] -  +++ Please report issues using the Support portal +++
[ECMWF-INFO -sbatch] -  +++ https://support.ecmwf.int                     +++
[ECMWF-INFO -sbatch] -  /usr/local/bin/ecsbatch: size: 53801, mtime: Tue Nov 25 12:31:30 2025
[ECMWF-INFO -sbatch] - -------------------------------------------------------------------------------------
[ECMWF-INFO -sbatch] - Time at submit: Fri Dec 12 12:43:21 2025 (1765543401.7041607) on ac6-102.bullx:/lus/h2resw01/hpcperm/nld4584/Anemoi_S2S_experiment/slurm_scripts
[ECMWF-INFO -sbatch] - --- SLURM VARIABLES ---
[ECMWF-INFO -sbatch] - EC_CLUSTER=ac
[ECMWF-INFO -sbatch] - SLURM_EXPORT_ENV=ALL
[ECMWF-INFO -sbatch] - SBATCH_EXPORT=NONE
[ECMWF-INFO -sbatch] - -----------------------
[ECMWF-INFO -sbatch] - jobscript: /lus/h2resw01/hpcperm/nld4584/Anemoi_S2S_experiment/slurm_scripts/test_warm_up_PINNLoss.sh
[ECMWF-INFO -sbatch] - --- SCRIPT OPTIONS ---
[ECMWF-INFO -sbatch] - #SBATCH --job-name=test_warmup_PINNLoss
[ECMWF-INFO -sbatch] - #SBATCH --output=./slurm_scripts/output_slurm/test_warmup_PINNLoss2-%J.out
[ECMWF-INFO -sbatch] - #SBATCH --error=./slurm_scripts/output_slurm/test_warmup_PINNLoss2-%J.out
[ECMWF-INFO -sbatch] - #SBATCH --chdir=/ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment
[ECMWF-INFO -sbatch] - #SBATCH --qos=ng
[ECMWF-INFO -sbatch] - #SBATCH --time=01:00:00
[ECMWF-INFO -sbatch] - #SBATCH --partition=gpu
[ECMWF-INFO -sbatch] - #SBATCH --gres=gpu:1
[ECMWF-INFO -sbatch] - #SBATCH --mem=60G
[ECMWF-INFO -sbatch] - -----------------------
[ECMWF-INFO -sbatch] - --- POST-PROCESSED OPTIONS ---
[ECMWF-INFO -sbatch] - ARG --positional=['./test_warm_up_PINNLoss.sh']
[ECMWF-INFO -sbatch] - ARG --chdir=/ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment
[ECMWF-INFO -sbatch] - ARG --error=./slurm_scripts/output_slurm/test_warmup_PINNLoss2-%J.out
[ECMWF-INFO -sbatch] - ARG --gres=gpu:1
[ECMWF-INFO -sbatch] - ARG --job_name=test_warmup_PINNLoss
[ECMWF-INFO -sbatch] - ARG --output=./slurm_scripts/output_slurm/test_warmup_PINNLoss2-%J.out
[ECMWF-INFO -sbatch] - ARG --partition=gpu
[ECMWF-INFO -sbatch] - ARG --qos=ng
[ECMWF-INFO -sbatch] - ARG --time=01:00:00
[ECMWF-INFO -sbatch] - ARG --mem=60G
[ECMWF-INFO -sbatch] - ------------------------------
[ECMWF-INFO -sbatch] - jobtag: nld4584-test_warmup_PINNLoss-1x2-/lus/h2resw01/hpcperm/nld4584/Anemoi_S2S_experiment/slurm_scripts/./slurm_scripts/output_slurm/test_warmup_PINNLoss2-_.out
[ECMWF-INFO -sbatch] - ['/usr/bin/sbatch', '--chdir=/ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment', '--error=./slurm_scripts/output_slurm/test_warmup_PINNLoss2-%J.out', '--gres=gpu:1', '--job-name=test_warmup_PINNLoss', '--output=./slurm_scripts/output_slurm/test_warmup_PINNLoss2-%J.out', '--partition=gpu', '--qos=ng', '--time=01:00:00', '--mem=60G', '--licenses=h2resw01', '--export=EC_user_time_limit=01:00:00', '/lus/h2resw01/hpcperm/nld4584/Anemoi_S2S_experiment/slurm_scripts/test_warm_up_PINNLoss.sh']
[ECMWF-INFO -sbatch] - sbatch executed on ac
[ECMWF-INFO -sbatch] - Job queued on ac using method local
[ECMWF-INFO -sbatch] - Submitted batch job 37923352
[ECMWF-INFO -ecprofile] /usr/bin/bash NON_INTERACTIVE on ac6-312 at 20251212_124344.792, PID: 324843, JOBID: 37923352
[ECMWF-INFO -ecprofile] $SCRATCH=/ec/res4/scratch/nld4584
[ECMWF-INFO -ecprofile] $PERM=/perm/nld4584
[ECMWF-INFO -ecprofile] $HPCPERM=/ec/res4/hpcperm/nld4584
[ECMWF-INFO -ecprofile] $TMPDIR=/dev/shm/_tmpdir_.nld4584.37923352
[ECMWF-INFO -ecprofile] $SCRATCHDIR=/ec/res4/scratchdir/nld4584/0/37923352
2025-12-12 12:50:12 INFO Running anemoi training command with overrides: ['--config-name=test_warm_up_PINNLoss.yaml']
2025-12-12 12:51:08 INFO Prepending Anemoi Config Env (/ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/Configs_new/Training) to the search path.
2025-12-12 12:51:08 INFO Prepending current user directory (/lus/h2resw01/hpcperm/nld4584/Anemoi_S2S_experiment) to the search path.
2025-12-12 12:51:08 INFO Search path is now: [provider=anemoi-cwd-searchpath-plugin, path=/lus/h2resw01/hpcperm/nld4584/Anemoi_S2S_experiment, provider=anemoi-env-searchpath-plugin, path=/ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/Configs_new/Training, provider=hydra, path=pkg://hydra.conf, provider=main, path=pkg://anemoi.training/config]
[2025-12-12 12:51:10,356][anemoi.training.train.train][INFO] - Skipping config validation.
[2025-12-12 12:51:10,357][anemoi.training.train.train][INFO] - Starting from checkpoint: True
[2025-12-12 12:51:10,358][anemoi.training.train.train][INFO] - Run id: bf9da25f-ed0b-42db-9164-cd71b2f75ecc
[2025-12-12 12:51:10,358][anemoi.training.train.train][INFO] - Checkpoints path: output_training/checkpoint/bf9da25f-ed0b-42db-9164-cd71b2f75ecc
[2025-12-12 12:51:10,358][anemoi.training.train.train][INFO] - Plots path: output_training/plots/bf9da25f-ed0b-42db-9164-cd71b2f75ecc
/lus/h2resw01/hpcperm/nld4584/anemoi_core_2025_17_11/anemoi-utils/src/anemoi/utils/config.py:207: UserWarning: Mofifying and instance of DotDict(). This class is intended to be immutable.
  warnings.warn("Mofifying and instance of DotDict(). This class is intended to be immutable.")
[2025-12-12 12:51:45,924][anemoi.graphs.nodes.builders.from_file][INFO] - Reading the dataset from /home/mlx/ai-ml/datasets//aifs-ea-an-oper-0001-mars-o96-1979-2023-6h-v8.zarr.
[2025-12-12 12:51:51,409][anemoi.utils.config][INFO] - Using environment variable ANEMOI_CONFIG_PATH to override the anemoi config key 'path.'
[2025-12-12 12:52:02,135][anemoi.graphs.edges.builders.cutoff][INFO] - Using CutOff-Edges (with radius = 144.6 km) between data and hidden.
[2025-12-12 12:52:03,196][anemoi.graphs.edges.builders.base][WARNING] - The 'torch-cluster' library is not installed. Installing 'torch-cluster' can significantly improve performance for graph creation. You can install it using 'pip install torch-cluster'.
[2025-12-12 12:52:13,814][anemoi.graphs.edges.builders.knn][INFO] - Using KNN-Edges (with 3 nearest neighbours) between hidden and data.
[2025-12-12 12:52:13,815][anemoi.graphs.edges.builders.base][WARNING] - The 'torch-cluster' library is not installed. Installing 'torch-cluster' can significantly improve performance for graph creation. You can install it using 'pip install torch-cluster'.
[2025-12-12 12:52:13,877][anemoi.graphs.create][INFO] - Cleaning graph.
[2025-12-12 12:52:13,877][anemoi.graphs.create][INFO] - _grid_reference_distance deleted from graph.
[2025-12-12 12:52:13,877][anemoi.graphs.create][INFO] - _dataset deleted from graph.
[2025-12-12 12:52:13,877][anemoi.graphs.create][INFO] - _grid_reference_distance deleted from graph.
[2025-12-12 12:52:14,376][anemoi.graphs.create][INFO] - Graph saved at graphs/graph.pkl.
[2025-12-12 12:52:15,373][anemoi.training.data.datamodule.singledatamodule][WARNING] - Falling back rollout to: 1
[2025-12-12 12:52:15,374][anemoi.training.data.datamodule.singledatamodule][INFO] - Timeincrement set to 1 for data with frequency, 21600, and timestep, 21600
[2025-12-12 12:52:15,376][anemoi.training.train.train][INFO] - Number of data variables: 101
[2025-12-12 12:52:15,376][anemoi.training.train.train][INFO] - Training limits: max_epochs=50, max_steps=300. Training will stop when either limit is reached first. Learning rate scheduler will run for 300000 steps.
[2025-12-12 12:53:14,553][anemoi.training.diagnostics.callbacks.plot][INFO] - Setting up asynchronous plotting ...
[2025-12-12 12:53:14,555][anemoi.training.diagnostics.callbacks.plot][INFO] - Setting up asynchronous plotting ...
[2025-12-12 12:53:14,604][anemoi.training.diagnostics.callbacks.plot][INFO] - Setting up asynchronous plotting ...
[2025-12-12 12:53:14,604][anemoi.training.diagnostics.callbacks.plot][INFO] - Using defined accumulation colormap for fields: ['tp', 'cp']
[2025-12-12 12:53:14,606][anemoi.training.diagnostics.callbacks.plot][INFO] - Setting up asynchronous plotting ...
[2025-12-12 12:53:14,608][anemoi.training.diagnostics.callbacks.plot][INFO] - Setting up asynchronous plotting ...
[2025-12-12 12:53:14,608][anemoi.training.diagnostics.callbacks.plot][INFO] - Using precip histogram plotting method for fields: ['tp', 'cp'].
/lus/h2resw01/hpcperm/nld4584/anemoi_core_2025_17_11/venv_anemoi_core_2025_17_11/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /lus/h2resw01/hpcperm/nld4584/anemoi_core_2025_17_1 ...
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
[rank: 0] Seed set to 37923352
/lus/h2resw01/hpcperm/nld4584/anemoi_core_2025_17_11/anemoi-utils/src/anemoi/utils/provenance.py:143: UserWarning: The '__version__' attribute is deprecated and will be removed in MarkupSafe 3.1. Use feature detection, or `importlib.metadata.version("markupsafe")`, instead.
  versions[name] = str(module.__version__)
[2025-12-12 12:56:43,221][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_julian_day is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_latitude is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_local_time is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_longitude is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: insolation is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: lsm is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_julian_day is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_latitude is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_local_time is not normalized.
[2025-12-12 12:56:43,222][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_longitude is not normalized.
/lus/h2resw01/hpcperm/nld4584/anemoi_core_2025_17_11/anemoi-utils/src/anemoi/utils/config.py:207: UserWarning: Mofifying and instance of DotDict(). This class is intended to be immutable.
  warnings.warn("Mofifying and instance of DotDict(). This class is intended to be immutable.")
[2025-12-12 12:56:43,987][anemoi.models.layers.utils][INFO] - Linear kernel: torch.nn.Linear.
[2025-12-12 12:56:43,988][anemoi.models.layers.utils][INFO] - LayerNorm kernel: torch.nn.LayerNorm.
[2025-12-12 12:56:43,988][anemoi.models.layers.utils][INFO] - Activation kernel: torch.nn.GELU.
[2025-12-12 12:56:44,020][anemoi.models.layers.utils][INFO] - QueryNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.
[2025-12-12 12:56:44,020][anemoi.models.layers.utils][INFO] - KeyNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.
[2025-12-12 12:56:44,337][anemoi.models.layers.utils][INFO] - Linear kernel: torch.nn.Linear.
[2025-12-12 12:56:44,338][anemoi.models.layers.utils][INFO] - LayerNorm kernel: torch.nn.LayerNorm.
[2025-12-12 12:56:44,338][anemoi.models.layers.utils][INFO] - Activation kernel: torch.nn.GELU.
[2025-12-12 12:56:44,339][anemoi.models.layers.utils][INFO] - QueryNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.
[2025-12-12 12:56:44,340][anemoi.models.layers.utils][INFO] - KeyNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.
[2025-12-12 12:56:44,340][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,439][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,506][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,574][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,642][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,710][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,778][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,847][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,914][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:46,982][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:47,049][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:47,117][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:47,184][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:47,252][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:47,320][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:47,388][anemoi.models.layers.attention][INFO] - Using flash_attention
[2025-12-12 12:56:47,461][anemoi.models.layers.utils][INFO] - Linear kernel: torch.nn.Linear.
[2025-12-12 12:56:47,462][anemoi.models.layers.utils][INFO] - LayerNorm kernel: torch.nn.LayerNorm.
[2025-12-12 12:56:47,462][anemoi.models.layers.utils][INFO] - Activation kernel: torch.nn.GELU.
[2025-12-12 12:56:47,463][anemoi.models.layers.utils][INFO] - QueryNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.
[2025-12-12 12:56:47,463][anemoi.models.layers.utils][INFO] - KeyNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.
[2025-12-12 12:56:47,894][anemoi.training.losses.scalers.variable_level][INFO] - Variable Level Scaling: Applying ReluVariableLevelScaler scaling to pl variables ({'param': ['q', 't', 'u', 'v', 'w', 'z']})
[2025-12-12 12:56:47,894][anemoi.training.losses.scalers.variable_level][INFO] - with slope = 0.001 and y-intercept/minimum = 0.2.
[2025-12-12 12:56:48,116][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 2m temperature at index 3 via '2t'
[2025-12-12 12:56:48,116][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 2m dewpoint at index 2 via '2d'
[2025-12-12 12:56:48,116][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found surface pressure at index 20 via 'sp'
[2025-12-12 12:57:19,958][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 'mean' and 'stdev' variables in dataset for statistics
[2025-12-12 12:57:19,974][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: loaded statistics from dataset
[2025-12-12 12:57:19,975][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 2m temperature at index 3 via '2t'
[2025-12-12 12:57:19,975][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 2m dewpoint at index 2 via '2d'
[2025-12-12 12:57:19,975][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found surface pressure at index 20 via 'sp'
[2025-12-12 12:57:20,086][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 2m temperature at index 3 via '2t'
[2025-12-12 12:57:20,087][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 2m dewpoint at index 2 via '2d'
[2025-12-12 12:57:20,087][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found surface pressure at index 20 via 'sp'
[2025-12-12 12:57:20,087][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 2m temperature at index 3 via '2t'
[2025-12-12 12:57:20,087][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found 2m dewpoint at index 2 via '2d'
[2025-12-12 12:57:20,087][anemoi.training.losses.PINNmse][INFO] - PINNMSELoss: found surface pressure at index 20 via 'sp'
[2025-12-12 12:57:20,553][anemoi.training.train.train][INFO] - The following submodules will NOT be trained: []
[2025-12-12 12:57:20,576][anemoi.training.train.train][INFO] - Resuming training from last checkpoint: /ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/checkpoints_mariana/louca/last.ckpt
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

Restoring states from the checkpoint path at /ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/checkpoints_mariana/louca/last.ckpt
/lus/h2resw01/hpcperm/nld4584/anemoi_core_2025_17_11/venv_anemoi_core_2025_17_11/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:366: The dirpath has changed from '/lus/h2resw01/scratch/momc/aifs/o96/checkpoint/5440dece28cd4ae98338a283815a05a1' to '/lus/h2resw01/hpcperm/nld4584/Anemoi_S2S_experiment/output_training/checkpoint/bf9da25f-ed0b-42db-9164-cd71b2f75ecc', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[rank: 0] Seed set to 37923352

  | Name    | Type                 | Params | Mode 
---------------------------------------------------------
0 | model   | AnemoiModelInterface | 231 M  | train
1 | loss    | PINNMSELoss          | 0      | train
2 | metrics | ModuleDict           | 0      | train
---------------------------------------------------------
231 M     Trainable params
0         Non-trainable params
231 M     Total params
924.556   Total estimated model params size (MB)
278       Modules in train mode
0         Modules in eval mode
Restored all states from the checkpoint at /ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/checkpoints_mariana/louca/last.ckpt
/lus/h2resw01/hpcperm/nld4584/anemoi_core_2025_17_11/venv_anemoi_core_2025_17_11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-12-12 12:58:24,041][anemoi.training.data.dataset.singledataset][INFO] - Worker 1 (pid 347041, global_rank 0, model comm group 0)  has low/high range 7670 / 15340
[2025-12-12 12:58:24,047][anemoi.training.data.dataset.singledataset][INFO] - Worker 2 (pid 347043, global_rank 0, model comm group 0)  has low/high range 15340 / 23010
[2025-12-12 12:58:24,052][anemoi.training.data.dataset.singledataset][INFO] - Worker 3 (pid 347046, global_rank 0, model comm group 0)  has low/high range 23010 / 30680
[2025-12-12 12:58:24,058][anemoi.training.data.dataset.singledataset][INFO] - Worker 0 (pid 347039, global_rank 0, model comm group 0)  has low/high range 0 / 7670
[2025-12-12 12:58:24,084][anemoi.training.data.dataset.singledataset][INFO] - Worker 0 (train, pid 347039, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 37923352, sanity rnd 0.977595)
[2025-12-12 12:58:24,084][anemoi.training.data.dataset.singledataset][INFO] - Worker 2 (train, pid 347043, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 37923352, sanity rnd 0.977595)
[2025-12-12 12:58:24,085][anemoi.training.data.dataset.singledataset][INFO] - Worker 3 (train, pid 347046, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 37923352, sanity rnd 0.977595)
[2025-12-12 12:58:24,088][anemoi.training.data.dataset.singledataset][INFO] - Worker 1 (train, pid 347041, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 37923352, sanity rnd 0.977595)
[2025-12-12 12:58:24,106][anemoi.training.data.dataset.singledataset][INFO] - Worker 4 (pid 347048, global_rank 0, model comm group 0)  has low/high range 30680 / 38350
[2025-12-12 12:58:24,109][anemoi.training.data.dataset.singledataset][INFO] - Worker 4 (train, pid 347048, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 37923352, sanity rnd 0.977595)
[2025-12-12 12:58:24,155][anemoi.training.data.dataset.singledataset][INFO] - Worker 5 (pid 347050, global_rank 0, model comm group 0)  has low/high range 38350 / 46020
[2025-12-12 12:58:24,158][anemoi.training.data.dataset.singledataset][INFO] - Worker 5 (train, pid 347050, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 37923352, sanity rnd 0.977595)
[2025-12-12 12:58:24,263][anemoi.training.data.dataset.singledataset][INFO] - Worker 6 (pid 347052, global_rank 0, model comm group 0)  has low/high range 46020 / 53690
[2025-12-12 12:58:24,266][anemoi.training.data.dataset.singledataset][INFO] - Worker 6 (train, pid 347052, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 37923352, sanity rnd 0.977595)
[2025-12-12 12:58:24,313][anemoi.training.data.dataset.singledataset][INFO] - Worker 7 (pid 347054, global_rank 0, model comm group 0)  has low/high range 53690 / 61360
[2025-12-12 12:58:24,316][anemoi.training.data.dataset.singledataset][INFO] - Worker 7 (train, pid 347054, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 37923352, sanity rnd 0.977595)
`Trainer.fit` stopped: `max_steps=300` reached.
[2025-12-12 12:58:29,423][anemoi.training.diagnostics.callbacks.plot][INFO] - Teardown of the Plot Callback ...
[2025-12-12 12:58:29,423][anemoi.training.diagnostics.callbacks.plot][INFO] - waiting and shutting down the executor ...
[2025-12-12 12:58:29,423][anemoi.training.diagnostics.callbacks.plot][INFO] - Teardown of the Plot Callback ...
[2025-12-12 12:58:29,424][anemoi.training.diagnostics.callbacks.plot][INFO] - waiting and shutting down the executor ...
[2025-12-12 12:58:29,424][anemoi.training.diagnostics.callbacks.plot][INFO] - Teardown of the Plot Callback ...
[2025-12-12 12:58:29,424][anemoi.training.diagnostics.callbacks.plot][INFO] - waiting and shutting down the executor ...
[2025-12-12 12:58:29,424][anemoi.training.diagnostics.callbacks.plot][INFO] - Teardown of the Plot Callback ...
[2025-12-12 12:58:29,424][anemoi.training.diagnostics.callbacks.plot][INFO] - waiting and shutting down the executor ...
[2025-12-12 12:58:29,424][anemoi.training.diagnostics.callbacks.plot][INFO] - Teardown of the Plot Callback ...
[2025-12-12 12:58:29,424][anemoi.training.diagnostics.callbacks.plot][INFO] - waiting and shutting down the executor ...
[ECMWF-INFO -ecepilog] ----------------------------------------------------------------------------------------------------
[ECMWF-INFO -ecepilog] This is the ECMWF job Epilogue
[ECMWF-INFO -ecepilog] +++ Please report issues using the Support portal +++
[ECMWF-INFO -ecepilog] +++ https://support.ecmwf.int                     +++
[ECMWF-INFO -ecepilog] ----------------------------------------------------------------------------------------------------
[ECMWF-INFO -ecepilog] Run at 2025-12-12T12:58:52 on ac
[ECMWF-INFO -ecepilog] JobName                   : test_warmup_PINNLoss
[ECMWF-INFO -ecepilog] JobID                     : 37923352
[ECMWF-INFO -ecepilog] Submit                    : 2025-12-12T12:43:21
[ECMWF-INFO -ecepilog] Start                     : 2025-12-12T12:43:42
[ECMWF-INFO -ecepilog] End                       : 2025-12-12T12:58:52
[ECMWF-INFO -ecepilog] QueuedTime                : 21.0
[ECMWF-INFO -ecepilog] ElapsedRaw                : 910
[ECMWF-INFO -ecepilog] ExitCode                  : 0:0
[ECMWF-INFO -ecepilog] DerivedExitCode           : 0:0
[ECMWF-INFO -ecepilog] State                     : COMPLETED
[ECMWF-INFO -ecepilog] Account                   : nlcko
[ECMWF-INFO -ecepilog] QOS                       : ng
[ECMWF-INFO -ecepilog] User                      : nld4584
[ECMWF-INFO -ecepilog] StdOut                    : /ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/./slurm_scripts/output_slurm/test_warmup_PINNLoss2-37923352.out
[ECMWF-INFO -ecepilog] StdErr                    : /ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/./slurm_scripts/output_slurm/test_warmup_PINNLoss2-37923352.out
[ECMWF-INFO -ecepilog] NNodes                    : 1
[ECMWF-INFO -ecepilog] NCPUS                     : 2
[ECMWF-INFO -ecepilog] SBU                       : 4.313
[ECMWF-INFO -ecepilog] jobtag                    : nld4584-test_warmup_PINNLoss-1x2-/ec/res4/hpcperm/nld4584/Anemoi_S2S_experiment/./slurm_scripts/output_slurm/test_warmup_PINNLoss2-_JOBID_.out
[ECMWF-INFO -ecepilog] ----------------------------------------------------------------------------------------------------

